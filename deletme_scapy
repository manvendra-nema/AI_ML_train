import requests
from bs4 import BeautifulSoup

# Base URL for pagination
base_url = "https://quotes.toscrape.com/page/{}/"

# Start with page 1 and continue until no quotes are found
page = 1
while True:
    url = base_url.format(page)
    response = requests.get(url)

    # If the page returns a 404 or doesn't exist, stop scraping
    if response.status_code != 200:
        print(f"Page {page} does not exist. Scraping stopped.")
        break

    soup = BeautifulSoup(response.content, "html.parser")

    # Check if "No quotes found!" message is present
    no_quotes = soup.find("div", class_="no_quotes")
    if no_quotes:
        print("No quotes found! Scraping stopped.")
        break

    # Find all quote containers on this page
    quotes = soup.find_all("div", class_="quote")

    # Extract and print each quote's text and author
    for quote in quotes:
        text = quote.find("span", class_="text").text
        author = quote.find("small", class_="author").text
        print(f"Quote: {text}")
        print(f"Author: {author}")
        print("-" * 40)

    # Move to the next page
    page += 1
